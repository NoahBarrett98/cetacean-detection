{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "import glob\n",
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification, ASTFeatureExtractor\n",
    "import torch\n",
    "sys.path.append(r\"C:\\Users\\NoahB\\OneDrive\\Desktop\\cetacean_detection\")\n",
    "from cetacean_detection.src.data.ast_dataset import generate_ast_dataset\n",
    "from cetacean_detection.src.data.pre_processor import PreProcessConfig\n",
    "from cetacean_detection.utils.config import Config, GeneralConfig\n",
    "config = r\"C:\\Users\\NoahB\\OneDrive\\Desktop\\cetacean_detection\\cetacean_detection\\configs\\pipeline.yaml\"\n",
    "configs = Config.from_yaml(config)\n",
    "config: PreProcessConfig = configs.get(\"preprocess\", PreProcessConfig())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NoahB\\AppData\\Local\\Temp\\ipykernel_18828\\2668401813.py:36: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "wav_dir = r\"C:\\Users\\NoahB\\OneDrive\\Desktop\\cetacean_detection\\nefsc_sbnms_200903_nopp6_ch10\\source-audio\"\n",
    "wav_files = glob.glob(os.path.join(wav_dir, \"*.wav\"))\n",
    "sampling_rate, X, y = generate_ast_dataset(wav_files[0], config)\n",
    "# the feature extractor can be geussed using the auto feature extractor\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\", sampling_rate=sampling_rate, num_mel_bins=40, max_length=40)\n",
    "\n",
    "feature_extractor = ASTFeatureExtractor(\n",
    "    sampling_rate=2000,\n",
    "    num_mel_bins=128,  # Adjust as needed\n",
    "    max_length=58,\n",
    "    do_normalize=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "positive_entry = np.array(X)[np.array(y) == 1][1]\n",
    "print(positive_entry.shape)\n",
    "negative_entry = np.array(X)[np.array(y) == 0][1]\n",
    "postive_inputs = feature_extractor(positive_entry.astype(float), sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "negative_inputs = feature_extractor(negative_entry.astype(float), sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "# Assuming inputs is your dictionary\n",
    "positive_tensor_data = postive_inputs['input_values'].squeeze(0)  # Remove batch dimension if necessary (1, 40, 40 -> 40, 40)\n",
    "negative_tensor_data = negative_inputs['input_values'].squeeze(0)  # Remove batch dimension if necessary (1, 40, 40 -> 40, 40)\n",
    "\n",
    "\n",
    "inputs = feature_extractor(positive_entry.astype(float), sampling_rate=sampling_rate, return_tensors=\"np\")\n",
    "\n",
    "spectrogram_features = inputs['input_values'][0]  # Extracted feature matrix\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(spectrogram_features.T, aspect='auto', origin='lower')\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.ylabel('Mel Frequency Bin')\n",
    "plt.xlabel('Time Frame')\n",
    "plt.title('AST Feature Extractor Spectrogram')\n",
    "plt.show()\n",
    "\n",
    "# Create subplots\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# # Plot positive entry\n",
    "# ax[0].imshow(positive_tensor_data, alpha=1.0)\n",
    "# ax[0].set_title('Positive Entry')\n",
    "# ax[0].axis('off')  # Optionally turn off axes\n",
    "\n",
    "# # Plot negative entry\n",
    "# ax[1].imshow(negative_tensor_data, alpha=1.0)\n",
    "# ax[1].set_title('Negative Entry')\n",
    "# ax[1].axis('off')  # Optionally turn off axes\n",
    "\n",
    "# # Show the plot\n",
    "# plt.colorbar(ax[0].images[0], ax=ax[0])\n",
    "# plt.colorbar(ax[1].images[0], ax=ax[1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 290/290 [00:00<00:00, 742.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed Mean: -3.509511783990341, Computed Std: 12.877285997576628\n",
      "-3.509511783990341\n",
      "12.877285997576628\n"
     ]
    }
   ],
   "source": [
    "# compute mean / std\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "extractor = ASTFeatureExtractor(\n",
    "    sampling_rate=2000,         # Match your audio sampling rate\n",
    "    num_mel_bins=128,           # Number of mel bins (adjustable)\n",
    "    max_length=58,              # Based on your previous calculation\n",
    "    do_normalize=False          # We compute mean and std, so disable for now\n",
    ")\n",
    "\n",
    "def compute_mean_std(extractor, dataset):\n",
    "    all_features = []\n",
    "\n",
    "    for audio in tqdm(dataset):\n",
    "        # Ensure audio is in numpy array format\n",
    "        if not isinstance(audio, np.ndarray):\n",
    "            audio = np.array(audio)\n",
    "        \n",
    "        # Extract features using the extractor\n",
    "        features = extractor._extract_fbank_features(audio, max_length=extractor.max_length)\n",
    "        all_features.append(features)\n",
    "\n",
    "    # Convert to a single array\n",
    "    all_features = np.concatenate(all_features, axis=0)  # shape: (total_frames, num_mel_bins)\n",
    "\n",
    "    # Compute mean and std\n",
    "    mean = np.mean(all_features)\n",
    "    std = np.std(all_features)\n",
    "\n",
    "    print(f\"Computed Mean: {mean}, Computed Std: {std}\")\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(extractor, np.array(X).astype(float))\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NoahB\\AppData\\Local\\Temp\\ipykernel_18828\\2108109147.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ASTFeatureExtractor(\n",
    "    sampling_rate=2000,\n",
    "    num_mel_bins=128,  # Adjust as needed\n",
    "    max_length=58,\n",
    "    do_normalize=True,\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n",
    "\n",
    "inputs = feature_extractor(positive_entry.astype(float), sampling_rate=sampling_rate, return_tensors=\"np\")\n",
    "\n",
    "spectrogram_features = inputs['input_values'][0]  # Extracted feature matrix\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(spectrogram_features.T, aspect='auto', origin='lower')\n",
    "plt.colorbar(label='Intensity')\n",
    "plt.ylabel('Mel Frequency Bin')\n",
    "plt.xlabel('Time Frame')\n",
    "plt.title('AST Feature Extractor Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  37.29552868534483\n",
      "std:  24.15963634614625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NoahB\\AppData\\Local\\Temp\\ipykernel_18828\\3595545552.py:30: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "processed_Data_file_1 = r\"C:\\Users\\NoahB\\OneDrive\\Desktop\\cetacean_detection\\nefsc_sbnms_200903_nopp6_ch10\\processed\\intial_run\\images\\NOPP6_EST_20090328_000000_CH10.npz\"\n",
    "\n",
    "data = np.load(processed_Data_file_1)\n",
    "positive_tensor_data = data[\"X\"][data[\"y\"] == 1][1]\n",
    "negative_tensor_data = data[\"X\"][data[\"y\"] == 0][1]\n",
    "\n",
    "mean = np.mean(data[\"X\"])\n",
    "std = np.std(data[\"X\"])\n",
    "print(\"mean: \", mean)\n",
    "print(\"std: \", std)\n",
    "    \n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot positive entry\n",
    "ax[0].imshow(positive_tensor_data, alpha=1.0)\n",
    "ax[0].set_title('Positive Entry')\n",
    "ax[0].axis('off')  # Optionally turn off axes\n",
    "\n",
    "# Plot negative entry\n",
    "ax[1].imshow(negative_tensor_data, alpha=1.0)\n",
    "ax[1].set_title('Negative Entry')\n",
    "ax[1].axis('off')  # Optionally turn off axes\n",
    "\n",
    "# Show the plot\n",
    "plt.colorbar(ax[0].images[0], ax=ax[0])\n",
    "plt.colorbar(ax[1].images[0], ax=ax[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to reproduce the spectrogram generation with torch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ASTForAudioClassification were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
      "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 1523, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0733, -0.2175]])\n"
     ]
    }
   ],
   "source": [
    "model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\", num_mel_bins = 400, max_length=400, ignore_mismatched_sizes=True)\n",
    "# Customize the classifier head (change 10 to your desired number of classes)\n",
    "num_classes = 2\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.LayerNorm(768),\n",
    "    torch.nn.Linear(768, num_classes)\n",
    ")\n",
    "model\n",
    "\n",
    "positive_tensor_data = data[\"X\"][data[\"y\"] == 1][1]\n",
    "positive_tensor_data = torch.from_numpy(positive_tensor_data.astype(np.float32)).unsqueeze(0)\n",
    "positive_tensor_data.shape\n",
    "inputs = {'input_values': positive_tensor_data}\n",
    "with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "print(logits)\n",
    "# predicted_class_ids = torch.argmax(logits, dim=-1).item()\n",
    "# predicted_label = model.config.id2label[predicted_class_ids]\n",
    "# predicted_label\n",
    "\n",
    "# # compute loss - target_label is e.g. \"down\"\n",
    "# target_label = model.config.id2label[0]\n",
    "# inputs[\"labels\"] = torch.tensor([model.config.label2id[target_label]])\n",
    "# loss = model(**inputs).loss\n",
    "# print(round(loss.item(), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original ast model (pretrained with imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=1521\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\NoahB\\OneDrive\\Desktop\\cetacean_detection\\ast\\src\\models\")\n",
    "\n",
    "from ast_models import ASTModel\n",
    "ast_mdl = ASTModel(label_dim=2, input_tdim=400, input_fdim=400, model_size='tiny224')\n",
    "# input a batch of 10 spectrogram, each with 100 time frames and 128 frequency bins\n",
    "test_output = ast_mdl(positive_tensor_data)\n",
    "# output should be in shape [10, 527], i.e., 10 samples, each with prediction of 527 classes.\n",
    "print(test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (c_det)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
